version: '3.8'

services:
  vision-ai:
    build: .
    container_name: vision-ai
    restart: always
    ports:
      - "3000:3000" # HTTP
      - "3001:3001" # HTTPS
    environment:
      - PORT=3000
      # For Windows/Mac Docker Desktop, use host.docker.internal to reach host's Ollama
      - OLLAMA_BASE_URL=http://host.docker.internal:11434
    env_file:
      - .env
    extra_hosts:
      - "host.docker.internal:host-gateway" # Required for Linux support to access host
